# World's First Fully NPU-Supported RAG Pipeline

## About
This is the **world's first fully NPU-supported RAG pipeline** running entirely on Qualcomm Snapdragon NPU with state-of-the-art models.

**What makes it special:**
- ðŸ”’ **100% Private** â€” All processing happens locally, nothing leaves your device
- âš¡ **10Ã— More Power Efficient** â€” Runs on NPU instead of GPU
- ðŸŒŸ **State-of-the-art Models** â€” Best-in-class embedding, reranking, and generation
- ðŸ”Œ **Always-On** â€” Efficient enough to run as a background service

![The Stack](./architecture.png)

**The Stack:**
- **Embedding:** Gemma-300M (Google DeepMind) â€” Top multilingual embedding model
- **Rerank:** Jina Reranker v2 â€” SOTA cross-lingual reranking
- **Generation:** NexaAI/Llama3.2-3B-NPU-Turbo
- **Runtime:** NexaML with OpenAI-compatible APIs

Bring your own files (PDFs, Word docs, text) and ask questionsâ€”the system retrieves relevant context and generates answers entirely on your device.

## Examples
- [Python-Binding-Example](./Python-Binding-Example/README.md)
- [Serve-Example](./Serve-Example/README.md)
