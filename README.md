# RAG with Nexa Serve

## 1. About
This project is a lightweight **Retrieval-Augmented Generation (RAG)** system built on top of **[nexa serve](https://github.com/NexaAI/nexa-sdk)** with the **Qwen3-4B** model.  

The system lets you bring your own files — such as **PDFs, Word docs, text files** — and automatically builds a small database from them. When you ask a question, the model retrieves relevant chunks from your files and responds based on the resources you provided.  

You can run the system directly from the **CLI**, or launch a simple **Gradio UI** for an interactive experience.


## 2. Preparation
Before running this project, make sure you have the **Nexa SDK** windows arm64 installed.
Once installed, you need to download the **embeddinggemma-300m-npu, jina-v2-rerank-npu, Granite-4-Micro-NPU model** with the following command:
```bash
nexa pull NexaAI/embeddinggemma-300m-npu
nexa pull NexaAI/jina-v2-rerank-npu
nexa pull NexaAI/Granite-4-Micro-NPU
```

After the model is ready, start the Nexa server in a separate terminal:

```bash
nexa serve
```

Then back to this project, create a new conda environment (optional) and install dependencies:

```bash
# Create a new conda environment (optional)
conda create -n rag-nexa python=3.10 -y
conda activate rag-nexa

# install python dependencies
pip install -r requirements.txt
```


## 3. Run from CLI
To run the RAG pipeline from the command line:

```bash
python rag_nexa.py --rebuild
```

**Note:** The system automatically creates a `nexa-rag-docs` folder in your Downloads directory to store your documents. You can also specify a custom folder with `--data /path/to/your/docs`.

### Adding files
- Place your files into the `Downloads\nexa-rag-docs` folder (created automatically). Supported formats: **.pdf, .txt, .docx**  
- After adding new files, you need to **rebuild** the index by running with `--rebuild` flag or typing `:reload` in the CLI.  
  Rebuilding is required because it re-indexes the new files so the model can use them.

Once running, simply type your question in the terminal and the system will answer using your documents.


## 4. Run with Gradio UI
You can also start an interactive **Gradio web UI**:

```bash
python gradio_ui.py
```

Open the browser at [http://127.0.0.1:7860](http://127.0.0.1:7860).  

### Using the UI
- On the **left panel**, you can:
  - Upload new files into the documents folder (PDFs, docs, txts).
  - Click **Rebuild** after uploading to refresh the database.
- On the **right panel**, use the chat window to ask questions.
- The model will **stream answers** based on your documents.