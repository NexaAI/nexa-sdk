[
  {
    "id": "Llama3.2-3B-NPU-Turbo-NPU",
    "displayName": "Llama3.2-3B-NPU-Turbo-NPU",
    "modelName": "files-1-2.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/Llama3.2-3B-NPU-Turbo-NPU-mobile/",
    "modelUrl": "files-1-2.nexa"
  },
  {
    "id": "Llama-3.2-3B-Instruct-GGUF",
    "displayName": "Llama-3.2-3B-Instruct-GGUF",
    "modelName": "Llama-3.2-3B-Instruct-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0.gguf"
  },
  {
    "id": "Qwen3-4B-Instruct-2507-npu",
    "displayName": "Qwen3-4B-Instruct-2507-npu",
    "modelName": "files-1-1.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/Qwen3-4B-Instruct-2507-npu-mobile/",
    "modelUrl": "files-1-1.nexa"
  },
  {
    "id": "gpt-oss-20b-GGUF",
    "displayName": "gpt-oss-20b-GGUF",
    "modelName": "gpt-oss-20b-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q4_0.gguf"
  },
  {
    "id": "Qwen3-4B-GGUF",
    "displayName": "Qwen3-4B-GGUF",
    "modelName": "Qwen3-4B-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_0.gguf"
  },
  {
    "id": "Granite-4-Micro-NPU",
    "displayName": "Granite-4.0-Micro 3B",
    "modelName": "files-1-2.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/Granite-4-Micro-NPU-mobile/",
    "modelUrl": "files-1-2.nexa"
  },
  {
    "id": "LFM2-1.2B-npu",
    "displayName": "LFM2-1.2B-npu",
    "modelName": "files-1-2.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/LFM2-1.2B-npu-mobile/",
    "modelUrl": "files-1-2.nexa"
  },
  {
    "id": "LFM2.5-1.2B-mobile",
    "displayName": "LFM2.5-1.2B-npu",
    "modelName": "files-1-2.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/LFM2.5-1.2B-mobile/",
    "modelUrl": "files-1-2.nexa"
  },
  {
    "id": "OmniNeural-4B",
    "displayName": "OmniNeural-4B",
    "modelName": "files-1-1.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/OmniNeural-4B-mobile/",
    "modelUrl": "files-1-1.nexa"
  },
  {
    "id": "paddleocr-npu",
    "displayName": "paddleocr-npu",
    "modelName": "weights-1-1.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/paddleocr-npu-mobile/",
    "modelUrl": "weights-1-1.nexa"
  },
  {
    "id": "yolo26x-npu",
    "displayName": "yolo26x-npu",
    "modelName": "weights-1-1.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/yolo26x-npu-mobile/",
    "modelUrl": "weights-1-1.nexa"
  },
  {
    "id": "depth-anything-v2-npu",
    "displayName": "depth-anything-v2-npu",
    "modelName": "weights-1-1.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/depth-anything-v2-npu-mobile/",
    "modelUrl": "weights-1-1.nexa"
  },
  {
    "id": "embeddinggemma-300m-npu",
    "displayName": "embeddinggemma-300m-npu",
    "modelName": "files-1-2.nexa",
    "versionCode": 1,
    "baseUrl": "https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/huggingface-models/embeddinggemma-300m-npu-mobile/",
    "modelUrl": "files-1-2.nexa"
  },
  {
    "id": "LFM2-1.2B-GGUF-GGUF",
    "displayName": "LFM2-1.2B-GGUF-GGUF",
    "modelName": "LFM2-1.2B-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_0.gguf"
  },
  {
    "id": "Llama-3.2-1B-Instruct-GGUF",
    "displayName": "Llama-3.2-1B-Instruct-GGUF",
    "modelName": "Llama-3.2-1B-Instruct-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf"
  },
  {
    "id": "LFM2-24B-A2B-Preview-GGUF",
    "displayName": "LFM2-24B-A2B-Preview-GGUF",
    "modelName": "LFM2-24B-A2B-Preview-Q4_0.gguf",
    "type": "chat",
    "versionCode": 1,
    "pluginIds": 17,
    "modelUrl": "https://huggingface.co/NexaAI/LFM2-24B-A2B-Preview-GGUF/resolve/main/LFM2-24B-A2B-Preview-Q4_0.gguf"
  }
]
